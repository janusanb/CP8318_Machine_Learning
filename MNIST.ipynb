{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The implementation of the program is entirely mine, except for the Neural Network which was originally inspired and implemented by Eu Jin Lok's work on Audio Processing https://www.kaggle.com/ejlok1/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans, FeatureAgglomeration, MeanShift, AgglomerativeClustering\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(dirList)\n",
    "M_train = np.loadtxt('digit-recognizer/train.csv', delimiter=',', skiprows=1)\n",
    "MNISTDF_train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "#MNISTDF_test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
    "#MNISTDF_sample = pd.read_csv(\"digit-recognizer/sample_submission.csv\")\n",
    "display(M_train)\n",
    "#display(MNISTDF_test)\n",
    "#display(MNISTDF_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#MNISTDF_test = pd.concat([MNISTDF_test, MNISTDF_sample], axis = 1)\n",
    "#MNISTDF_test = MNISTDF_test.drop(columns=[\"ImageId\"])\n",
    "#print(MNISTDF_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_binary_one = MNISTDF_train[MNISTDF_train.label == 1]\n",
    "MNISTDF_train_binary_zero = MNISTDF_train[MNISTDF_train.label == 0]\n",
    "#MNISTDF_test_binary_one = MNISTDF_test[MNISTDF_test.Label == 1]\n",
    "#MNISTDF_test_binary_zero = MNISTDF_test[MNISTDF_test.Label == 0]\n",
    "#display(MNISTDF_test_binary_one)\n",
    "#display(MNISTDF_test_binary_zero)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero], ignore_index=True)\n",
    "#MINST_test = pd.concat([MNISTDF_test_binary_one, MNISTDF_test_binary_zero], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "#MINST_test = MINST_test.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "#display(MINST_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[0, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[4, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x_training, y_training, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs').fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svmClass = SVC(kernel = 'linear')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.cluster import KMeans, FeatureAgglomeration, MeanShift, AgglomerativeClustering\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KMClassList = []\n",
    "for i in range(1, 10):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KMClassList = []\n",
    "for i in range(1, 10):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)\n",
    "\n",
    "MeanClass = MeanShift()\n",
    "MeanClass.fit(x_train, y_train)\n",
    "predictedMeanClass = MeanClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")\n",
    "\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=2, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=2, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(np.unique(vFeaturedf[\"VoxCeleb1 ID\"].shape))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the previous example, the accuracy score was 0%. This means for the previous example every prediction was the opposite."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=15, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Actual labels\n",
    "# actual = y_test.argmax(axis=1)\n",
    "# actual = actual.astype(int).flatten()\n",
    "# actual = (lb.inverse_transform((actual)))\n",
    "# actual = pd.DataFrame({'actualvalues': actual})\n",
    "\n",
    "# # Lets combined both of them into a single dataframe\n",
    "# finaldf = actual.join(preds)\n",
    "# finaldf[:]\n",
    "\n",
    "# print(y_test.argmax(axis=1))\n",
    "# finalY_test = y_test.argmax(axis=1)\n",
    "# predictedClassLabels = []\n",
    "# actualClassLabels = []\n",
    "# for index, i in enumerate(preds['predictedvalues']):\n",
    "#     predictedClassLabels.append(TransformedClassLabels[i])\n",
    "#     actualClassLabels.append(TransformedClassLabels[i])\n",
    "\n",
    "# #print(predictedClassLabels)\n",
    "# #print(actualClassLabels)\n",
    "# data = [predictedClassLabels, actualClassLabels]\n",
    "# print(data[0])\n",
    "# print(data[1])\n",
    "# finaldf = pd.DataFrame(data, columns=['Predicted Class Labels', \"Actual Class Labels\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_two = MNISTDF_train[MNISTDF_train.label == 2]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[12990, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[12990])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_test)\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "svmClass = SVC(kernel = 'linear')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svmClass = SVC(kernel = 'rbf')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "MeanClass = MeanShift()\n",
    "MeanClass.fit(x_train, y_train)\n",
    "predictedMeanClass = MeanClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=3, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_three = MNISTDF_train[MNISTDF_train.label == 3]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[1, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svmClass = SVC(kernel = 'linear')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print()\n",
    "svmClass = SVC(kernel = 'rbf')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=4, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(np.unique(vFeaturedf[\"VoxCeleb1 ID\"].shape))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_four = MNISTDF_train[MNISTDF_train.label == 4]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three, MNISTDF_train_four], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[1, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\").fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svmClass = SVC(kernel = 'linear')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print()\n",
    "svmClass = SVC(kernel = 'rbf')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMCLassList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(KMClassList)\n",
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(np.unique(vFeaturedf[\"VoxCeleb1 ID\"].shape))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_five = MNISTDF_train[MNISTDF_train.label == 5]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three, MNISTDF_train_four, MNISTDF_train_five], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[25209, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[25209])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\").fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svmClass = SVC(kernel = 'linear')\n",
    "svmClass.fit(x_train, y_train)\n",
    "predictedSVM = svmClass.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "#print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print()\n",
    "# svmClass = SVC(kernel = 'rbf')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# #print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=6, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_six = MNISTDF_train[MNISTDF_train.label == 6]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three, MNISTDF_train_four, MNISTDF_train_five, MNISTDF_train_six], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[29344, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[29344])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\").fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# svmClass = SVC(kernel = 'linear')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# #print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()\n",
    "\n",
    "# print()\n",
    "# svmClass = SVC(kernel = 'rbf')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# #print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)\n",
    "\n",
    "# print(KMClassList)\n",
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=7, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_seven = MNISTDF_train[MNISTDF_train.label == 7]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three, MNISTDF_train_four,\n",
    "                         MNISTDF_train_five, MNISTDF_train_six, MNISTDF_train_seven], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[78, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\").fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# svmClass = SVC(kernel = 'linear')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()\n",
    "\n",
    "# print()\n",
    "# svmClass = SVC(kernel = 'rbf')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# #print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)\n",
    "\n",
    "# print(KMClassList)\n",
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=8, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_eight = MNISTDF_train[MNISTDF_train.label == 8]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three, MNISTDF_train_four,\n",
    "                         MNISTDF_train_five, MNISTDF_train_six, MNISTDF_train_seven, MNISTDF_train_eight], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[37808, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[37808])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\").fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# svmClass = SVC(kernel = 'linear')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()\n",
    "\n",
    "# print()\n",
    "# svmClass = SVC(kernel = 'rbf')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# #print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)\n",
    "\n",
    "# print(KMClassList)\n",
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=9, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(9)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MNISTDF_train_nine = MNISTDF_train[MNISTDF_train.label == 9]\n",
    "MINST_train = pd.concat([MNISTDF_train_binary_one, MNISTDF_train_binary_zero, MNISTDF_train_two, MNISTDF_train_three, MNISTDF_train_four,\n",
    "                         MNISTDF_train_five, MNISTDF_train_six, MNISTDF_train_seven, MNISTDF_train_eight, MNISTDF_train_nine], ignore_index=True)\n",
    "MINST_train = MINST_train.sample(frac=1).reset_index(drop = True)\n",
    "display(MINST_train)\n",
    "exportingMINST_train = MINST_train.drop(columns=['label'])\n",
    "exportCheck = exportingMINST_train.to_csv(\"convert_to_numpy.csv\", index=False)\n",
    "n_inputs = 784\n",
    "x_training = MINST_train.iloc[:, MINST_train.columns != 'label']\n",
    "y_training = MINST_train.iloc[:, MINST_train.columns == 'label'] # Extract the last 7 elements - a one hot category encoding\n",
    "sampleImage = x_training.iloc[0].to_numpy\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MINST_train.drop(['label'], axis = 1),\n",
    "                                                    MINST_train.label, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainingset = np.loadtxt('convert_to_numpy.csv', delimiter=',', skiprows=1)\n",
    "print(trainingset)\n",
    "print(y_training)\n",
    "sampleindex = np.random.randint(0,1000)\n",
    "sample = trainingset[41996, :]\n",
    "sample = sample.reshape(28, 28)\n",
    "\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "print(y_training.iloc[41996])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "naive = NB()\n",
    "naive.fit(x_train, y_train)\n",
    "predictedNB = naive.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedNB)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logReg = LR(solver='lbfgs', multi_class=\"multinomial\").fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# svmClass = SVC(kernel = 'linear')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=0)\n",
    "DTC.fit(x_train, y_train)\n",
    "predictedDTC = DTC.predict(x_test)\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedDTC)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "logReg = LR(solver='lbfgs', multi_class=\"ovr\" ).fit(x_train, y_train)\n",
    "predictedLR = logReg.predict(x_test)\n",
    "print(\"The accuracy without applying PCA is: %.4f\"%(metrics.accuracy_score(y_test, predictedLR)),\"\\n\")\n",
    "print()\n",
    "\n",
    "# print()\n",
    "# svmClass = SVC(kernel = 'rbf')\n",
    "# svmClass.fit(x_train, y_train)\n",
    "# predictedSVM = svmClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedSVM)), \"\\n\")\n",
    "# #print(confusion_matrix(bin_label_test, predictedSVM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "KMClassList = []\n",
    "for i in range(1, 11):\n",
    "  KMClass = KMeans(n_clusters=i)\n",
    "  KMClass.fit(x_train, y_train)\n",
    "  predictedKMClass = KMClass.predict(x_test)\n",
    "  print(\"The accuracy without applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedKMClass)), \"\\n\")\n",
    "  KMClassList.append(metrics.accuracy_score(y_test, predictedKMClass))\n",
    "\n",
    "print(KMClassList)\n",
    "\n",
    "# print(KMClassList)\n",
    "# print(np.unique(y_test))\n",
    "# MeanClass = MeanShift()\n",
    "# MeanClass.fit(x_train, y_train)\n",
    "# predictedMeanClass = MeanClass.predict(x_test)\n",
    "# print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, predictedMeanClass)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "AlgoClass = AgglomerativeClustering(n_clusters=10, affinity=\"euclidean\", linkage=\"ward\")\n",
    "predictedAlgo = AlgoClass.fit(x_train, y_train)\n",
    "AlgoClass.fit_predict(x_test)\n",
    "print(AlgoClass.labels_)\n",
    "print(y_test)\n",
    "\n",
    "print(\"The accuracy after applying PCA is: %.4f\" %(metrics.accuracy_score(y_test, AlgoClass.labels_)), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)# np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = lb.fit_transform(y_test)# np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(x_train.shape)\n",
    "display(y_train)\n",
    "print(lb.classes_)\n",
    "\n",
    "filename = 'labelsVox'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()\n",
    "#display(y_train)\n",
    "x_train = np.expand_dims(x_train, axis = 2)\n",
    "x_test = np.expand_dims(x_test, axis = 2)\n",
    "#x_train = np.squeeze(x_train)\n",
    "#x_test = np.squeeze(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(x_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=50, epochs=25, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#----------------------------------------------#----------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}